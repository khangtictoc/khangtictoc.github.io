---
title: Consistent Hashing Algorithm In Disk & Database
author: khangtictoc
date: 2025-06-11 00:34:00 +0800
categories: [Theory]
tags: [storage, database]
---

## ğŸ§¾ Goal

- Simulate how keys are mapped to partitions (nodes) using **Consistent Hashing**.
- Then simulate what happens when you add a new partition.
- Show how only some keys are remapped (not all, unlike naive hash % N).

## âš™ï¸ Setup

- **Hash Ring Range**: `0 - 99` (for simplicity)  
  _(Real systems may use a space like `0` to `2Â³Â²` or `2â¶â´`, but `0â€“99` makes it easier to follow)_

### ğŸ§± Initial Partitions (Nodes)

| Node | Hash Position |
| ---- | ------------- |
| A    | 10            |
| B    | 40            |
| C    | 70            |

### ğŸ§‘ Sample Keys (Users)

| Key     | `Hash(key)` (simulated) |
| ------- | ----------------------- |
| alice   | 15                      |
| bob     | 43                      |
| charlie | 67                      |
| dave    | 84                      |
| eve     | 5                       |

## âœ… Step 1: Place Keys on Ring and Assign to Nodes

### Rules

- Keys go to the **next node clockwise**.
- If a key's hash exceeds the highest node, it wraps around to node at the lowest position.

### ğŸ”— Assignment

| Key     | Hash | Assigned Node | Reason                |
| ------- | ---- | ------------- | --------------------- |
| eve     | 5    | A (10)        | 5 â†’ next â‰¥ 10         |
| alice   | 15   | B (40)        | 15 â†’ next â‰¥ 40        |
| bob     | 43   | C (70)        | 43 â†’ next â‰¥ 70        |
| charlie | 67   | C (70)        | 67 â†’ next â‰¥ 70        |
| dave    | 84   | A (10, wrap)  | 84 â†’ wrap â†’ next â‰¥ 10 |

## ğŸ“Š Initial Mapping Summary

| Node | Keys Assigned |
| ---- | ------------- |
| A    | eve, dave     |
| B    | alice         |
| C    | bob, charlie  |

## â• Step 2: Add New Node D at Hash Position 50

### ğŸ†• Updated Nodes

- A (10)
- B (40)
- **D (50)**
- C (70)

### ğŸ”„ Recalculate Assignments

| Key     | Hash | New Assigned Node | Previously |
| ------- | ---- | ----------------- | ---------- |
| eve     | 5    | A (10)            | A          |
| alice   | 15   | B (40)            | B          |
| bob     | 43   | **D (50)**        | C âœ… moved |
| charlie | 67   | C (70)            | C          |
| dave    | 84   | A (10, wrap)      | A          |

## ğŸ“‰ Impact of Adding Node D

| Key    | Moved?         |
| ------ | -------------- |
| bob    | âœ… Yes (C â†’ D) |
| Others | âŒ No          |

> Only **one key (`bob`)** was remapped â€” this demonstrates the efficiency of consistent hashing.

## ğŸ“Œ Visual Ring Representation (Simplified)

```
  0           25           50           75          99
   +-----------+------------+------------+-----------+
   |           |            |            |           |
 [A-10]     [B-40]      [D-50]       [C-70]        wrap
   ^           ^            ^            ^
   |           |            |            |
 eve,dave    alice         bob        charlie
```

## ğŸ§  Why Consistent Hashing is Great

| Feature                     | Benefit                   |
| --------------------------- | ------------------------- |
| Key hash independent of `N` | Stable unless key changes |
| Only a subset of keys move  | Scales easily             |
| Balanced load (with vnodes) | More even distribution    |

## ğŸ§® How Do We Get Node D at Hash Position 50?

### âœ… Short Answer

> The node's hash position is calculated using the **same hash function** used for keys, applied to the node's **unique identifier** (e.g., `"NodeD"`).

### ğŸ” Step-by-Step

#### 1. Choose an Identifier

- `"NodeD"`
- Or something like `"192.168.0.4:8080"` or `"server-004"`

#### 2. Apply the Hash Function

```python
# Simplified example
hash("NodeD") % 100  â†’ 50
```

> This gives **Node D** a position of **50** on the ring.

#### 3. Use Consistent Hash Function

```python
import hashlib

def get_ring_position(node_id, ring_size=100):
    hash_bytes = hashlib.md5(node_id.encode()).digest()
    hash_int = int.from_bytes(hash_bytes, byteorder='big')
    return hash_int % ring_size

get_ring_position("NodeD")  # â†’ e.g., 50
```

## ğŸ¯ Bonus: Why Use Virtual Nodes?

| Node   | Virtual Node Positions |
| ------ | ---------------------- |
| Node D | 50, 73, 91             |

- Using **virtual nodes** (multiple positions per node) helps avoid uneven load.
- This is especially useful if nodes end up clustered in the hash space.

## ğŸŒ Real-World Uses of Consistent Hashing

Consistent hashing is widely used in modern distributed systems for scalability, fault tolerance, and load balancing.

### âœ… Distributed Databases & Caches

#### ğŸ”¹ Amazon DynamoDB

- Uses consistent hashing to partition data and support horizontal scaling.

#### ğŸ”¹ Apache Cassandra

- Each node owns a range on the ring.
- New nodes join by taking part of the range, minimal key movement.

#### ğŸ”¹ Memcached

- In multi-node deployments, consistent hashing ensures that only a small subset of keys are remapped when a node is added/removed.

### ğŸŒ Content Delivery Networks (CDNs)

#### ğŸ”¹ Akamai, Cloudflare

- Use hashing to assign content or requests to edge servers.
- Minimal rebalance on server change.

### âš–ï¸ Load Balancers

#### ğŸ”¹ NGINX, Envoy

- Hash-based load balancing (e.g., hash by IP) supports sticky sessions.
- Adding/removing backends only affects affected client hashes.

### ğŸ—„ï¸ Object Storage Systems

#### ğŸ”¹ Ceph, OpenStack Swift

- Consistent hashing determines where objects are stored across many disks/nodes.

### ğŸ” Service Mesh / Routing

#### ğŸ”¹ Istio, Linkerd

- Traffic routing based on consistent hashing of keys (like user IDs) to maintain session stickiness or shard requests.

### ğŸ“¬ Pub/Sub and Messaging Systems

#### ğŸ”¹ Apache Kafka

- Partitions are often chosen by key-based hashing.
- Consumers scale predictably with minimal rebalance.

### ğŸ§  DNS Load Balancing

#### ğŸ”¹ Netflix, Google

- Use hash-based routing to send users to the same edge nodes or POPs based on IP or region.

---

### ğŸ§  Why Itâ€™s So Popular

| Feature           | Benefit                          |
| ----------------- | -------------------------------- |
| Minimal remapping | Only affected keys move          |
| Scalable          | Add/remove nodes easily          |
| Predictable       | Same key â†’ same node             |
| Fast              | Hashing is computationally cheap |
| Stateless         | No central coordinator needed    |

## âœ… Final Summary

- Each **key** is hashed into a number (0â€“99).
- Itâ€™s then assigned to the **next node clockwise**.
- When you **add a new node**, only **some keys** (between previous and new node) are remapped.
